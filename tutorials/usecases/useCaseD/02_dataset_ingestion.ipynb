{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingesting a Q0 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database is now ready to be ingested to EOTDL. We just need to add the general metadata of the dataset in a README file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"---\n",
    "name: Sentinel-2-Ships\n",
    "authors: \n",
    "  - Pierre-Jean Coquard\n",
    "license: free\n",
    "source: https://github.com/earthpulse/eotdl/tree/main/tutorials/usecases/useCaseD\n",
    "---\n",
    "\n",
    "# Sentinel-2-Ships\n",
    "\n",
    "This is an example dataset created for the use case D.\n",
    "\"\"\"\n",
    "\n",
    "with open(\"data/sentinel_2/README.md\", \"w\") as outfile:\n",
    "    outfile.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eotdl.datasets import ingest_dataset\n",
    "\n",
    "ingest_dataset(\"data/sentinel_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can upgrade this dataset to a Q1 dataset by adding STAC metadata. We use the `STACCGenerator` class to automaticaly generate the STAC metadata for the whole dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eotdl.curation.stac.stac import STACGenerator\n",
    "from eotdl.curation.stac.assets import STACAssetGenerator\n",
    "from eotdl.curation.stac.parsers import UnestructuredParser\n",
    "from eotdl.curation.stac.dataframe_labeling import UnlabeledStrategy, LabeledStrategy\n",
    "\n",
    "stac_generator = STACGenerator(item_parser=UnestructuredParser, \n",
    "                               assets_generator=STACAssetGenerator, \n",
    "                               labeling_strategy=LabeledStrategy,\n",
    "                               image_format='tif'\n",
    "                               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stac_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m bands \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mship\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB01\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB02\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB03\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB04\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB05\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB06\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB07\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB08\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB09\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB11\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB12\u001b[39m\u001b[38;5;124m'\u001b[39m)}\n\u001b[1;32m      3\u001b[0m collection \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mship\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentinel-2-ships\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mstac_generator\u001b[49m\u001b[38;5;241m.\u001b[39mget_stac_dataframe(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/sentinel_2\u001b[39m\u001b[38;5;124m'\u001b[39m, collections\u001b[38;5;241m=\u001b[39mcollection, extensions\u001b[38;5;241m=\u001b[39mextensions, bands\u001b[38;5;241m=\u001b[39mbands)\n\u001b[1;32m      6\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stac_generator' is not defined"
     ]
    }
   ],
   "source": [
    "extensions = {'ship': ('proj', 'raster', 'eo')}\n",
    "bands = {'ship': ('B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B09', 'B11', 'B12')}\n",
    "collection = {'ship': 'sentinel-2-ships'}\n",
    "\n",
    "df = stac_generator.get_stac_dataframe('data/sentinel_2', collections=collection, extensions=extensions, bands=bands)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then generate the Stac metadata from the `STACDataframe` generated during the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sentinel-2-ships collection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:00<00:00, 239.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating and saving catalog...\n",
      "Success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stac_generator.generate_stac_metadata(stac_id='ship-segmentation-dataset',\n",
    "                                      description='Ship segmentation dataset',\n",
    "                                      output_folder='data/sentinel_2_stac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add the STAC metadata for the labels :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating labels collection...: 77it [00:00, 1838.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success on labels generation!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from eotdl.curation.stac.extensions import ScaneoLabeler\n",
    "\n",
    "labeler = ScaneoLabeler()\n",
    "\n",
    "catalog = 'data/sentinel_2_stac/catalog.json'\n",
    "labels_extra_properties = {'label_methods': [\"automated\"]}\n",
    "labeler.generate_stac_labels(\n",
    "    catalog=catalog,\n",
    "    root_folder='data/sentinel_2',\n",
    "    collection='sentinel-2-ships',\n",
    "    label_type=\"raster\",\n",
    "    **labels_extra_properties\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the STAC metadata is successfully generated, we can ingest the Q1 dataset into EOTDL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading STAC catalog...\n",
      "New version created, version: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [00:41<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting STAC catalog...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from eotdl.datasets import ingest_dataset\n",
    "\n",
    "ingest_dataset('data/sentinel_2_stac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating splits...\n",
      "Total size: 77\n",
      "Train size: 61\n",
      "Test size: 7\n",
      "Validation size: 7\n",
      "Generating Training split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:00<00:00, 11469.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Validation split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 8827.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Test split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 9966.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success on splits generation!\n",
      "Validating and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "from eotdl.curation.stac.extensions import add_ml_extension\n",
    "import pystac\n",
    "catalog = 'data/sentinel_2_stac/catalog.json'\n",
    "\n",
    "add_ml_extension(\n",
    "\tcatalog,\n",
    "\tdestination='data/sentinel_2_q2',\n",
    "\tsplits=True,\n",
    "\tsplits_collection_id=\"labels\",\n",
    "\tname='Ship Segmentation Q2',\n",
    "\ttasks=['segmentation'],\n",
    "\tinputs_type=['satellite imagery'],\n",
    "\tannotations_type='raster',\n",
    "\tversion='0.1.0',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the quality metrics for the dataset to ensure that it can be ingested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLDatasetExtension\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Looking for spatial duplicates...: 308it [00:00, 6491.65it/s]\n",
      "Calculating classes balance...: 308it [00:00, 280531.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating and saving...\n",
      "Success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from eotdl.curation.stac.extensions import MLDatasetQualityMetrics\n",
    "\n",
    "catalog = 'data/sentinel_2_q2/catalog.json'\n",
    "\n",
    "MLDatasetQualityMetrics.calculate(catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally ingest the Q2 dataset into EOTDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Loading STAC catalog...\n",
      "New version created, version: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [01:01<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting STAC catalog...\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "[Errno 2] No such file or directory: '/home/pcoquard/git/eotdl_use_case_d/data/sentinel_2_q2/catalog.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meotdl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ingest_dataset\n\u001b[0;32m----> 5\u001b[0m \u001b[43mingest_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/sentinel_2_q2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/eotdl3.9/lib/python3.9/site-packages/eotdl/datasets/ingest.py:28\u001b[0m, in \u001b[0;36mingest_dataset\u001b[0;34m(path, verbose, logger, force_metadata_update, sync_metadata)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPath must be a folder\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcatalog.json\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m [f\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m path\u001b[38;5;241m.\u001b[39miterdir()]:\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mingest_stac\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcatalog.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ingest_folder(path, verbose, logger, force_metadata_update, sync_metadata)\n",
      "File \u001b[0;32m~/miniforge3/envs/eotdl3.9/lib/python3.9/site-packages/eotdl/auth/auth.py:61\u001b[0m, in \u001b[0;36mwith_auth.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     60\u001b[0m     user \u001b[38;5;241m=\u001b[39m auth()\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/eotdl3.9/lib/python3.9/site-packages/eotdl/datasets/ingest.py:166\u001b[0m, in \u001b[0;36mingest_stac\u001b[0;34m(stac_catalog, logger, user)\u001b[0m\n\u001b[1;32m    163\u001b[0m data, error \u001b[38;5;241m=\u001b[39m repo\u001b[38;5;241m.\u001b[39mingest_stac(json\u001b[38;5;241m.\u001b[39mloads(df\u001b[38;5;241m.\u001b[39mto_json()), dataset_id, user)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# TODO: delete all assets that were uploaded\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error)\n\u001b[1;32m    167\u001b[0m logger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: [Errno 2] No such file or directory: '/home/pcoquard/git/eotdl_use_case_d/data/sentinel_2_q2/catalog.json'"
     ]
    }
   ],
   "source": [
    "from eotdl.datasets import ingest_dataset\n",
    "\n",
    "ingest_dataset('data/sentinel_2_q2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'validate_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcatalog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_all\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'validate_all'"
     ]
    }
   ],
   "source": [
    "catalog.validate_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eotdl3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
